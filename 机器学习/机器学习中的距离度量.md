# 机器学习中的距离度量

**距离度量**，英文为
$$
\text{distance measure}
$$

## 表示

* 函数或运算符
    * $\operatorname{dist}(\cdot, \cdot)$ 
    * $\operatorname{D}(\cdot, \cdot)$
* 范数
    * $ L_p = \left\|\boldsymbol{x}_{i}-\boldsymbol{x}_{j}\right\|_{p} $

## 性质

|  性质  | 公式                                                         |
| :----: | ------------------------------------------------------------ |
| 非负性 | $\operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \geqslant 0$ |
| 同一性 | $\operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) = 0 \Leftrightarrow \boldsymbol{x_i} = \boldsymbol{x_j}$ |
| 对称性 | $\operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) = \operatorname{dist}\left(\boldsymbol{x}_{j}, \boldsymbol{x}_{i}\right)$ |
| 直传性 | $\operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \leqslant \operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{k}\right)+\operatorname{dist}\left(\boldsymbol{x}_{k}, \boldsymbol{x}_{j}\right)$ |

## 常见距离度量

> 距离也被记作范数（`norm`）的形式

### 闵可夫斯基距离

$$
\operatorname{dist}_{m k}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\left(\sum_{u=1}^{n}\left|x_{i u}-x_{j u}\right|^{p}\right)^{\frac{1}{p}}=\left\|\boldsymbol{x}_{i}-\boldsymbol{x}_{j}\right\|_{p}
$$

其中，$p$ 为常数。当 $p \geqslant 1$ 时，其满足距离度量的定义。

### 曼哈顿距离

当闵可夫斯基距离的中的参数 $p = 1$ 时得到
$$
\operatorname{dist}_{\operatorname{man}}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\sum_{u=1}^{n}\left|x_{i u}-x_{j u}\right|=\left\|\boldsymbol{x}_{i}-\boldsymbol{x}_{j}\right\|_{1}
$$

### 欧式距离

当闵可夫斯基距离的中的参数 $p = 2$ 时得到
$$
\operatorname{dist}_{ed}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\sqrt{\sum_{u=1}^{n}\left|x_{i u}-x_{j u}\right|^{2}}=\left\|\boldsymbol{x}_{i}-\boldsymbol{x}_{j}\right\|_{2}
$$

### 切比雪夫距离

当闵可夫斯基距离的中的参数 $p \to \infty$ 时得到
$$
\operatorname{dist}_{chebyshev}=\left\|\boldsymbol{x}_{i}-\boldsymbol{x}_{j}\right\|_{\infty}
$$
